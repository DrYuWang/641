\documentclass[12pt]{amsart}

\usepackage{mathrsfs, fullpage, amsmath, amssymb, graphicx, xcolor, tikz}

\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\hat}{\widehat}
\newcommand{\bx}{\boldsymbol{x}}
\newcommand{\by}{\boldsymbol{y}}
\newcommand{\cA}{\mathscr{A}}
\newcommand{\cB}{\mathscr{B}}
\newcommand{\cC}{\mathscr{C}}
\newcommand{\cD}{\mathscr{D}}
\newcommand{\cF}{\mathscr{F}}
\newcommand{\cG}{\mathscr{G}}
\newcommand{\cN}{\mathscr{N}}
\newcommand{\cO}{\mathscr{O}}
\newcommand{\cP}{\mathscr{P}}
\newcommand{\cX}{\mathscr{X}}
\newcommand{\cY}{\mathscr{Y}}
\newcommand{\PP}{\mathbb{P}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}
\newcommand{\lra}{\longrightarrow}
\newcommand{\One}{\mathbf{1}}
\newcommand{\blank}{\,\cdot\,}

\newcommand{\vpi}{\boldsymbol{\pi}}
\newcommand{\vtheta}{\boldsymbol{\theta}}
\newcommand{\ve}{\boldsymbol{e}}
\newcommand{\vu}{\boldsymbol{u}}
\newcommand{\vv}{\boldsymbol{v}}
\newcommand{\vw}{\boldsymbol{w}}
\newcommand{\vx}{\boldsymbol{x}}
\newcommand{\vy}{\boldsymbol{y}}
\newcommand{\vz}{\boldsymbol{z}}
\newcommand{\vU}{\boldsymbol{U}}
\newcommand{\vV}{\boldsymbol{V}}
\newcommand{\vW}{\boldsymbol{W}}
\newcommand{\vX}{\boldsymbol{X}}
\newcommand{\vY}{\boldsymbol{Y}}
\newcommand{\vZ}{\boldsymbol{Z}}

\newcommand{\xhat}{\hat{x}}
\newcommand{\yhat}{\hat{y}}
\newcommand{\bxhat}{\hat{\bx}}
\newcommand{\byhat}{\hat{\by}}
\newcommand{\betahat}{\hat{\beta}}

\newcommand{\iid}{i.i.d.\ }

\DeclareMathOperator{\Bias}{Bias}
\DeclareMathOperator{\EE}{E}
\DeclareMathOperator{\Cov}{Cov}
\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\Var}{Var}
\DeclareMathOperator{\Mult}{Mult}
\DeclareMathOperator{\Ber}{Ber}
\DeclareMathOperator{\var}{var}
\DeclareMathOperator{\mean}{mean}
\DeclareMathOperator{\MSE}{MSE}
\DeclareMathOperator{\SSE}{SSE}
\DeclareMathOperator{\ESS}{ESS}
\DeclareMathOperator{\RSS}{RSS}
\DeclareMathOperator{\TSS}{TSS}
\DeclareMathOperator{\argmin}{argmin}
\DeclareMathOperator{\Argmin}{\mathop{\argmin}}


\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{thmdef}[theorem]{Theorem-Definition}

\setlength\parskip{0.5em}
\setlength\parindent{0em}

\definecolor{orange}{HTML}{FF7F0E}
\definecolor{green}{HTML}{2CA02C}
\definecolor{blue}{HTML}{1F77B4}

\DeclareRobustCommand\orangeline{\raisebox{0.5ex}{\tikz \draw[orange, thick] (1, 0) -- (0.5, 0);}}
\DeclareRobustCommand\blueline{\raisebox{0.5ex}{\tikz \draw[blue, thick] (1, 0) -- (0.5, 0);}}

\begin{document}
\part*{Introduction}

Statistical learning theory:
Inferring quantities, functions, class assignments, \ldots
using data and assumptions about its distribution.

Making inferences from training data, together with assumptions about its distribution,
for the purpose of making predictions about test (new) data.

\section{Learning from data}

\textbf{Point estimation:}
Estimate a population parameter $\theta$ of a random observable $X$ from sample data
$x_1,\ldots,x_p$ and assumptions about their distribution.

\textbf{Examples:}
\begin{enumerate}
    \setlength\itemsep{0.5em}
    \item Find an estimate, $\hat\theta$ of the average height of an adult German from a
    sample $x_1,\ldots,x_p$ of the heights of $p$ randomly selected individuals.
    \item[($1'$)] Find an estimate ${\hat\theta}_f$ (resp., ${\hat\theta}_m$) of the average height of 
    a German female (resp., male) from a sample $x_1,\ldots,x_p$ of the heights (not genders!) of $p$ randomly selected individuals
    under the assumption that the heights of females and males are each normally distributed.
    This is an \emph{incomplete data problem}.    
\end{enumerate}


\textbf{Function estimation:}
Find a plausible relationship $Y\approx \hat f(X)$ between random observables
$X$ and $Y$ from data $(x_1,y_1),\ldots,(x_p, y_p)$ and assumptions about their distribution.
When $Y$ is continuous (resp., discrete) this is typically called \emph{regression}
(resp., classification).

\textbf{Examples:}
\begin{enumerate}
\item Let $X$ and $Y$ be the height and weight of a randomly selected adult German female, respectively.
Find the ``best'' approximation to $Y$  as a function of $X$ assuming
\begin{itemize}
    \item $X$ and $Y$ are jointly normal.
    \item $Y|X$ is normal with constant variance.
    \item nothing.
\end{itemize}

% \item Suppose that an $n$-dimensional random vector $\vX$ is correlated with infection by a
% dangerous virus. While an expensive treatment for this virus is already available,
% measuring $\vX$ is relatively cheap.
% Design a test
% \[
%     \hat f:\RR^n\to\{0,1\}
% \]
% for the disease with a low false-positive rate and a \emph{very} low false-negative rate.

\item Armed with a large training set $(x_1, y_1),\ldots,(x_p, y_p)$ where $x_j$ is an image and
$y_j=1$ if $x_j$ contains a cat and $y_j=0$ otherwise, find a function
\[
    \hat{f}:\{\text{images}\}\lra \{0,1\}
\]
such that if $x\neq x_j$ is an image, then $\hat f(x)$ is likely to be $1$ if $x$ contains a cat and is likely to be $0$, otherwise.
\item Call an image $x$ an \emph{occlusion} of an image $y$ if $x$ made from $y$ by overlaying it with a small white patch.
Given a large training set $(x_1, y_1),\ldots,(x_p, y_p)$ where $y_j$ is an image and $x_j$ is an occlusion of $y_j$,
find a function
$$
\hat{f}:\{\text{images}\}\lra \{\text{images}\}
$$
such that if $y\neq y_j$ is an image of and $x$ is an occlusion of $y$, then $\hat f(x)\approx y$.
\end{enumerate}

\textbf{Questions:}
\begin{enumerate}
    \item How can we find good point/function estimates?
    \item How can we compare different point/function estimates? Is there a ``best'' estimate?
\end{enumerate}

\end{document}