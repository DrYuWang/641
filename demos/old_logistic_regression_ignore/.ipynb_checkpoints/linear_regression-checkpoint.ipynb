{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch import Tensor, ones, rand_like, cat, matmul, add, sub, nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.],\n",
      "        [1., 2.],\n",
      "        [1., 4.],\n",
      "        [1., 6.],\n",
      "        [1., 8.]])\n",
      "tensor([ 3.0958,  2.2656,  1.5475,  0.7787, -0.0077])\n"
     ]
    }
   ],
   "source": [
    "xT = Tensor([[1, 1, 1, 1, 1], [0, 2, 4, 6, 8]])\n",
    "x = xT.transpose(0, 1)\n",
    "b = Tensor([3, -0.4])\n",
    "y0 = matmul(x, b)\n",
    "y = add(y0, 0.2*rand_like(y0))\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bhat = matmul(matmul(xT, x).inverse(), matmul(xT, y))\n",
    "yhat = matmul(x, bhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0005)\n",
      "tensor(0.0005)\n"
     ]
    }
   ],
   "source": [
    "e = sub(yhat, y)\n",
    "print(e.dot(e)/5)\n",
    "loss = nn.MSELoss()\n",
    "print(loss(yhat, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -3.0720, -14.1327])\n",
      "tensor([-1.8799, -7.1032])\n",
      "tensor([-1.2741, -3.5433])\n",
      "tensor([-0.9651, -1.7406])\n",
      "tensor([-0.8066, -0.8279])\n",
      "tensor([-0.7242, -0.3660])\n",
      "tensor([ 2.0872, -0.2229], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "B = Variable(Tensor([2, -0.5]),requires_grad=True)\n",
    "for i in range(6):\n",
    "    L = loss(matmul(X, B), y)\n",
    "    L.backward()\n",
    "    print(B.grad.data)\n",
    "    B = Variable(sub(B, 0.01*B.grad), requires_grad=True)\n",
    "\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0379, -0.3364], requires_grad=True)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(x, y):\n",
    "    xt = x.transpose(0, 1)\n",
    "    def F(b):\n",
    "        return 2*matmul(xt, sub(matmul(x, b), y))\n",
    "    return F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-15.3598, -70.6635])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G = gradient(x, y)\n",
    "G(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 2.0872, -0.2229], requires_grad=True)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = Tensor([2, -0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-185-5f925ca45cb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not callable"
     ]
    }
   ],
   "source": [
    "gradient(x, y)(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
